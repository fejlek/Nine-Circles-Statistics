---
title: "The First Circle: Linear Regression, Part One"
author: "Jiří Fejlek"
date: "2025-05-15"
output:
  md_document:
    variant: markdown_github
code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

## Life Expectancy (WHO)  dataset

<https://www.kaggle.com/datasets/lashagoch/life-expectancy-who-updated>
 
Data contains life expectancy, health, immunization, and economic and demographic information about 179 countries from 2000 to 2015:

<br/>

* **Country** 
* **Region**
* **Year** - Data observed from 2000 to 2015
* **Infant_deaths** - Infant deaths per 1000 population
* **Under_five_deaths** - Deaths of children under five years old per 1000 population
* **Adult_mortality** - Deaths of adults between 15 and 60 per 1000 population
* **Alcohol_consumption** - Alcohol consumption in liters of pure alcohol per capita for 15+ years old
* **Hepatitis_B** - Coverage (%)  of Hepatitis B (HepB3) immunization among 1-year-olds.
* **Measles** - Coverage (%) of Measles immunization among 1-year-olds
* **BMI** - Mean body mass index (BMI) of adult population 18+ 
* **Polio** - Coverage (%) of Polio (Pol3) immunization among 1-year-olds
* **Diptheria** - Coverage (%) of Diphtheria tetanus toxoid and pertussis (DTP3) immunization among 1-year-olds.
* **Incidents_HIV** - Incidents of HIV per 1000 population aged 15-49
* **GDP_per_capita** - GDP per capita in USD
* **Population_mln** - Total population in millions
* **Thinness_10-19** - Prevalence of thinness among adolescents aged 10-19 years: BMI < -2 standard deviations below the median
* **Thinness_5-9** - Prevalence of thinness among children aged 5-9 years: BMI < -2 standard deviations below the median
* **Schooling** - Average years that people aged 25+ spent in formal education
* **Developed** - Economically developed country (status in the World Trade Organization)
* **Developing** - Economically developing country (status in the World Trade Organization)
* **Life_expectancy** - Average life expectancy 

<br/>

In this demonstration of using linear regression, our objective will be to build a model to identify predictors that seem to have a significant effect on life expectancy based on this dataset.

We split this presentation into two parts: data preparation/exploration and creating a model for effect estimation.

<br/>
Let us start the data preparation/exploration part and load in the data, and display the first few rows to check that it loaded correctly.
<br/>
<br/>

```{r, message=FALSE}
library(readr)
life_expectancy <- read_csv('C:/Users/elini/Desktop/nine circles/Life-Expectancy-Data-Updated.csv')
```
```{r}
head(life_expectancy)
```

## Initial Data Exploration
<br/>
We start with a brief data exploration. We will mostly look for serious problems with the data such as missing values, nonsensical values, etc. Let us first look at the size of the dataset.
<br/>

```{r}
dim(life_expectancy)
```
<br/>
We have 2864 observations, one response we wish to model/predict (**Life_expectancy**), and 20 possible predictors. Let us check whether there are indeed 2864 full observations.
```{r}
any(is.na(life_expectancy))
```
<br/> 
No data entry is missing, and every country has a unique record for each year, i.e., there are no duplicate observations.
<br/> 
```{r}
any(duplicated(cbind(life_expectancy$Country,life_expectancy$Year)))
```

<br/>
Now, let us have a closer look at the predictors. Predictors **Economy_status_Developed** and **Economy_status_Developing** should be considered as one factor variable (every country is either developed or developing). Let us check that fact and make the appropriate changes.
<br/>

```{r}
## Economy_status_Developed and Economy_status_Developing should add up to a vector of ones
which(life_expectancy$Economy_status_Developed+life_expectancy$Economy_status_Developing != 1)

## Turn column Economy_status_Developed into a factor, rename the levels and the column, drop the redundant column
library(tibble)
library(dplyr)
life_expectancy$Economy_status_Developed <- factor(life_expectancy$Economy_status_Developed)
levels(life_expectancy$Economy_status_Developed) <- c('Developing','Developed')
life_expectancy <- life_expectancy %>% rename(Economy_status = Economy_status_Developed)
life_expectancy$Economy_status_Developing <- NULL

## Turn column Region into a factor while we are at it
life_expectancy$Region <- factor(life_expectancy$Region)
```

<br/>
The rest of the predictors are correctly specified as numerical. Let us check that their values make some sense.
<br/>

* Infant_deaths
```{r}
summary(life_expectancy$Infant_deaths)
```

* Under_five_deaths
```{r, echo=FALSE}
summary(life_expectancy$Under_five_deaths)
```

* Adult_mortality
```{r, echo=FALSE}
summary(life_expectancy$Adult_mortality)
```

* Alcohol_consumption
```{r, echo=FALSE}
summary(life_expectancy$Alcohol_consumption)
```

* Hepatitis_B
```{r, echo=FALSE}
summary(life_expectancy$Hepatitis_B)
```

* Measles
```{r, echo=FALSE}
summary(life_expectancy$Measles)
```
* Polio
```{r, echo=FALSE}
summary(life_expectancy$Polio)
```

* Diphtheria
```{r, echo=FALSE}
summary(life_expectancy$Diphtheria)
```

* Incidents_HIV
```{r, echo=FALSE}
summary(life_expectancy$Incidents_HIV)
```

* GDP_per_capita
```{r, echo=FALSE}
summary(life_expectancy$GDP_per_capita)
```

* Population_mln
```{r, echo=FALSE}
summary(life_expectancy$Population_mln)
```

* Thinness_ten_nineteen_years
```{r, echo=FALSE}
summary(life_expectancy$Thinness_ten_nineteen_years)
```

* Thinness_five_nine_years
```{r, echo=FALSE}
summary(life_expectancy$Thinness_five_nine_years)
```

* Schooling
```{r, echo=FALSE}
summary(life_expectancy$Schooling)
```


<br/>
None of the minimal or maximal values seems nonsensical. To conclude this initial exploration of the data, we plot histograms of all predictors to check whether all predictors are varied enough (i.e., we check whether some predictors should be omitted due to being non-informative for modelling/prediction purposes). Histograms also help us assess the overall distribution of the predictors.
<br/>


```{r fig.align = 'center', message=FALSE}
library(ggplot2)
library(gridExtra)

plot1 <- ggplot(life_expectancy, aes(x=Infant_deaths)) + geom_histogram() + xlab("Infant_deaths") + ylab("Frequency")
plot2 <- ggplot(life_expectancy, aes(x=Under_five_deaths)) + geom_histogram() + xlab("Under_five_deaths") + ylab("Frequency")
plot3 <- ggplot(life_expectancy, aes(x=Adult_mortality)) + geom_histogram() + xlab("Adult_mortality") + ylab("Frequency")
grid.arrange(plot1, plot2, plot3, ncol=3)
```

<br/> 
```{r fig.align = 'center', message=FALSE, echo=FALSE}
library(ggplot2)
library(gridExtra)
plot1 <- ggplot(life_expectancy, aes(x=Alcohol_consumption)) + geom_histogram() + xlab("Alcohol_consumption") + ylab("Frequency")
plot2 <- ggplot(life_expectancy, aes(x=Hepatitis_B)) + geom_histogram() + xlab("Hepatitis_B") + ylab("Frequency")
plot3 <- ggplot(life_expectancy, aes(x=Measles)) + geom_histogram() + xlab("Measles") + ylab("Frequency")
grid.arrange(plot1, plot2, plot3, ncol=3)
plot1 <- ggplot(life_expectancy, aes(x=BMI)) + geom_histogram() + xlab("BMI") + ylab("Frequency")
plot2 <- ggplot(life_expectancy, aes(x=Polio)) + geom_histogram() + xlab("Polio") + ylab("Frequency")
plot3 <- ggplot(life_expectancy, aes(x=Diphtheria)) + geom_histogram() + xlab("Diphtheria") + ylab("Frequency")
grid.arrange(plot1, plot2, plot3, ncol=3)
plot1 <- ggplot(life_expectancy, aes(x=Incidents_HIV)) + geom_histogram() + xlab("Incidents_HIV") + ylab("Frequency")
plot2 <- ggplot(life_expectancy, aes(x=GDP_per_capita )) + geom_histogram() + xlab("GDP_per_capita ") + ylab("Frequency")
plot3 <- ggplot(life_expectancy, aes(x=Population_mln)) + geom_histogram() + xlab("Population_mln") + ylab("Frequency")
grid.arrange(plot1, plot2, plot3, ncol=3)
plot1 <- ggplot(life_expectancy, aes(x=Thinness_ten_nineteen_years)) + geom_histogram() + xlab("Thinness_ten_nineteen_years") + ylab("Frequency")
plot2 <- ggplot(life_expectancy, aes(x=Thinness_five_nine_years)) + geom_histogram() + xlab("Thinness_five_nine_years") + ylab("Frequency")
plot3 <- ggplot(life_expectancy, aes(x=Schooling)) + geom_histogram() + xlab("Schooling") + ylab("Frequency")
grid.arrange(plot1, plot2, plot3, ncol=3)
```

<br/>
None of the numerical predictors seems nearly constant, so we will consider all of them for modelling now. I will just do a logarithm transformation of **Population_mln** and  **GDP_per_capita** to reduce their large spread of values (we do not expect that the effects of these predictors will have such a proportional spread). 
<br/>


```{r}
Population_log <- log(life_expectancy$Population_mln + 1)
GDP_log <- log(life_expectancy$GDP_per_capita)
life_expectancy <- life_expectancy %>% add_column(Population_log)
life_expectancy <- life_expectancy %>% add_column(GDP_log)
```
```{r fig.align = 'center', message=FALSE, echo=FALSE}
ggplot(life_expectancy, aes(x=Population_log)) + geom_histogram() + xlab("Population_log") + ylab("Frequency")
ggplot(life_expectancy, aes(x=GDP_log)) + geom_histogram() + xlab("GDP_log") + ylab("Frequency")
```

## Redundancy Analysis

<br/>
As we will discuss further in Part 2, we will model life expectancy using all predictors except **Country**, **Year**, and **Adult_mortality**. Our dataset consists of a relatively small number of predictors. However, the effective size of our dataset is also much smaller than which would appear at the first glance, as we discuss in Part Two.  Hence, it is worthwhile to check whether some predictors contain redundant information. We first plot a correlation heatmap.
<br/>

```{r fig.align = 'center',out.width="200%", message=FALSE}
library(pheatmap)
pheatmap(cor(life_expectancy[,c(4,5,7:13,16,17,18,21,22)]),display_numbers = TRUE, fontsize = 8, cluster_rows = FALSE, cluster_cols = FALSE)
```

<br/>

As can be seen from the heatmap, some predictors are significantly correlated. Let us test whether such predictors can indeed be modelled via the remaining predictors. We use a variance inflation factor (VIF) that considers the linear regression of every predictor against all other predictors. 

<br/>

```{r, message=FALSE}
library(car)
model <- lm(Life_expectancy ~ .  - Year - Country - Region - GDP_per_capita - Adult_mortality - Population_mln, data=life_expectancy)
vif(model)
```

<br/>
Since **Infant_deaths** and **Under_five_deaths** are almost perfectly collinear, we indeed observe that these two predictors have extremely high VIF, because one predictor can accurately model the other.
<br/>

```{r, message=FALSE}
## Show R^2 statistics for linear regression Infant_deaths ~ Under_five_deaths
summary(lm(Infant_deaths~Under_five_deaths,data = life_expectancy))$r.squared
```

<br/>
This fact will make estimating the corresponding regression coefficients in any model based on this data set extremely difficult because the data contains very little information about the effect of changing **Infant_deaths**  while holding **Under_five_deaths** constant and vice versa.

When faced with a group of collinear predictors, it is recommended to summarize the predictors instead of arbitrarily choosing one. In our case, we use principal component analysis (PCA). 

<br/>

```{r, message=FALSE}
# PCA
pc_infant_and_under_five <- prcomp(~life_expectancy$Infant_deaths+life_expectancy$Under_five_deaths,'scale' = TRUE,'center' = TRUE)
summary(pc_infant_and_under_five)

# Extract the first component and add it to the dataset
pc1 <- pc_infant_and_under_five$x[,1]
life_expectancy <- life_expectancy %>% add_column(pc1) %>% rename(Inf5_m = pc1)

# Coefficients for PC
pc_infant_and_under_five$rotation
```

<br/>
We can notice that since we have two almost perfectly collinear predictors, we obtain an equal proportion of both as the first principal component (after centering and rescaling to unit variance). We will use this first component as our new summarizing predictor. 

The second pair of collinear predictors that could be combined is **Polio** and **Diphtheria**, However, they are closer to the rule of thumb cutoff: VIF = 10. Hence, I chose to keep both for modelling. 
<br/>

```{r, message=FALSE}
summary(lm(Diphtheria~Polio,data = life_expectancy))$r.squared
```

<br/>
VIF considers only regression models in which all predictors enter linearly. We can consider a more sophisticated redundancy analysis using the function *redun*, which uses more flexible regression splines for predicting each variable from all others. We can see from the results that no more predictors seem excessively redundant (I chose a 0.95 R-squared cutoff).
<br/>

```{r, message=FALSE}
library(Hmisc)
redun(~.- Life_expectancy - Infant_deaths - Under_five_deaths - Year - Country  -  Adult_mortality - Population_mln - GDP_per_capita,data = life_expectancy,nk = 4, r2 = 0.95)
```
